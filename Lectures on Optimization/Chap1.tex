\chapter{Nonlinear Optimization}\label{chap:nonlinear_optimization}

In this chapter, we mainly focus on:
\begin{itemize}
    \item Main notations and concepts used in \emph{Continuous Optimization}.
    \item Complexity Analysis of the problems of Global Optimization.
    \item Local Minimization and 2 main methods: \emph{the Gradient Method} and \emph{the Newton Method}.
    \item Some standard methods in General Nonlinear Optimization.
\end{itemize}

\newpage
\section{The World of Nonlinear Optimization}\label{sec:the_world_of_nonlinear_optimization}

\subsection{General Formulation of the Problem}\label{subsec:general_formulation_of_the_problem}
Let \(\bm{x}\) be an \(n\)-dimensional \emph{real vector}
\[
    \bm{x} = \left( x^{(1)}, \dots, x^{(n)} \right)^\top \in \R^n
\]
and \(f_0(\cdot), \dots, f_m(\cdot)\) be some \emph{real-valued} functions defined on a set \(Q \subset \R^n\). In this way, let's consider the general minimization problem:
\begin{equation}\label{eq:general_min_problem}
    \begin{aligned}
        &\min ~ f_0(\bm{x}), \\
        &\text{s.t.}~f_j(\bm{x}) ~ \& ~ 0, \quad j = 1, \dots, m,\\
        &\bm{x} \in Q,
    \end{aligned}
\end{equation}
where the sign \(\&\) can be \(\le\), \(\ge\) or \(=\).

\begin{note}{Notations}
    \begin{itemize}
        \item \(f_0\) is called \emph{objective} function.
        \item The vector function \(\bm{f}(\bm{x}) = \left( f_1(\bm{x}), \dots, f_m(\bm{x})^\top \right)\) is called the vector of \emph{functional constraints}.
        \item The set \(Q\) is called the \emph{basic feasible set}.
        \item The set \( \mathscr{F} = \{ x \in Q \mid f_j(\bm{x}), ~j=1, \dots, m \}\) is called \emph{the entire feasible set} of problem~\ref{eq:general_min_problem}. 
    \end{itemize}
\end{note}

\begin{note}{Classification}
    \begin{enumerate}
        \item \textbf{Natural Classification}:
            \begin{itemize}
                \item \emph{Constrained problems}: \(\mathscr{F} \subset \R^n\).
                \item \emph{Unconstrained problems}: \(\mathscr{F} \equiv \R^n\).
                \item \emph{Smooth problems}: all \(f_j(\cdot)\) are differentiable.
                \item \emph{Nonsmooth problems}: there are several nondifferentiable components \(f_k(\cdot)\).
                \item \emph{Linearly constrained problems}: the functional constraints are affine:
                    \[
                            f_j(x) = \langle \bm{a}_j, \bm{x} \rangle + b_j
                    \]
                    \begin{itemize}
                        \item \emph{Linear optimization Problem}: \(f_0(\cdot)\) is also affine.
                        \item \emph{Quadratic optimization problem}: \(f_0(\cdot)\) is Quadratic.
                        \item \emph{Quadratic constrained quadratic problem}: \(f_0(\cdot), \dots, f_m(\cdot)\) are all quadratic.
                    \end{itemize}
            \end{itemize}
        \item \textbf{Based on the Feasible Set}:
            \begin{itemize}
                \item Problem~\ref{eq:general_min_problem} is called \emph{feasible} if \(\mathscr{F} \ne \emptyset\).
                \item Problem~\ref{eq:general_min_problem} is called \emph{strictly} feasible if there exists an \(\bm{x} \in Q\) such that \(f_j(\bm{x}) < 0\) for all inequality constraints and \(f_j(\bm{x}) = 0\) for all equality constraints. (\textit{Slater condition}.)
            \end{itemize}
        \item \textbf{Based on Solution}:
            \begin{itemize}
                \item A point \(\bm{x}^* \in \mathscr{F}\) is called the optimal \emph{global solution} to problem~\ref{eq:general_min_problem} if \(f_0(\bm{x}^*) \le f_0(\bm{x})\) for all \(\bm{x} \in \mathscr{F}\) (\textit{global minimum}). \(f_0(\bm{x}^*)\) is called the global \emph{optimal value} of the problem.
                \item A point \(\bm{x}^* \in \mathscr{F}\) is called a \emph{local solution} to problem~\ref{eq:general_min_problem} if there exists a set \(\hat{\mathscr{F}} \subset \mathscr{F}\) such that \(\forall \bm{x} \in \mathrm{int}\hat{\mathscr{F}}, ~f_0(\bm{x}^*) \le f_0(\bm{x})\). If \(\forall \bm{x} \in \hat{\mathscr{F}} \setminus \{\bm{{x}^*}\}, ~f_0(\bm{x}^*) \le f_0(\bm{x})\), then \(\bm{x}^*\) is called \emph{strict} (or \emph{isolated}) local minimum.
            \end{itemize}
    \end{enumerate}
\end{note}

Nonlinear Optimization is very import and promising application theory. It covers almost ALL needs of Operation Research and Numerical Analysis. However, in general, optimization problems should be UNSOLVABLE. It is difficult to believe in the existence of a universal tool which is able to solve all problems in the world.

\begin{boxnote}{Summerization}
    \begin{itemize}
        \item First we learn the general formulation of optimization problem in~\ref{eq:general_min_problem} and related concepts.
        \item We can also classify the optimization problems into different categories. The classification methods include:
              \begin{itemize}
                \item Natural Classification.
                \item Based on Feasible Set.
                \item Based on Solution.
              \end{itemize} 
    \end{itemize}
\end{boxnote}

\subsection{Performance of Numerical Methods}\label{subsec:performance_of_numerical_performance}
Usually we focus on the best method for a \emph{class} of problem \(\mathscr{P} \ni P\). The \emph{performance} of a method, \(\mathscr{M}\) on the whole class \(\mathscr{P}\) can be a natural measure of its efficiency. Here we assume that the method \(\mathscr{M}\) does not have \emph{complete} information about a particular problem \(P\).
\begin{itemize}
    \item \textbf{Model}: The \emph{model} is the \emph{known} (to a numerical scheme) "part" of problem \(P\) and is denoted by \(\Sigma\). The model consists of:
        \begin{itemize}
            \item The formulation of the problem.
            \item The description of the classes of functional components.
            \item etc.
        \end{itemize}    
    \item \textbf{Oracle}: The oracle is used to describe the process of collecting this data. A oracle \(\mathcal{O}\) is just a unit which answers the successive questions of the methods.
\end{itemize}
The method \(\mathscr{M}\) is trying to solve the problem \(P\) by collecting and handling the answers. 

For each problem we can develop different types of oracles. But let us fix \(\Sigma\) and \(\mathcal{O}\). In this case, it is natural to define the performance of \(\mathscr{M}\) on \((\Sigma, \mathcal{O})\) as its performance on the worst \(P_w\) from \((\Sigma, \mathcal{O})\). Note that \(P_w\) can be only bad for \(\mathscr{M}\).

\begin{defn}[Performance]\label{defn:performance}
    The performance of \(\mathscr{M}\) on \(P\) is the total amount of \emph{computational effort} required by the method \(\mathscr{M}\) to solve the problem \(P\).
\end{defn}

\begin{note}{Notes}
    \begin{itemize}
        \item Solving the problem means finding an \emph{approximate solution} to \(\mathscr{P}\) with some accuracy \(\epsilon > 0\). 
        \item We use \(\mathscr{T}_\epsilon\) to represent a stopping criterion.
    \end{itemize}
\end{note}

Now we have a formal description of the problem class:
\[
    \mathscr{P} \equiv (\Sigma, \mathcal{O}, \mathscr{T}_\epsilon)    
\]

In order to solve a problem \(P\) from \(\mathscr{P}\), we apply it to an \emph{iterative process}.
\begin{algorithm}[!htbp]
    \caption{General Iterative Scheme}\label{alg:general_iterative}
    \KwIn{Starting point \(x_0\) and accuracy \(\epsilon > 0\).}
    \KwOut{Solution \(\bar{x}\).}
    \textbf{Initialization}: Set \(k = 0\), \(\mathscr{I}_{-1} = \emptyset\). Here \(k\) is the iteration counter and \(\mathscr{I}_k\) is the accumulated \emph{informational set}.\\
    \While{True}{
        Call oracle \(\mathcal{O}\) at point \(\bm{x}_k\). \\
        Update the informational set: \(\mathscr{I}_k = \mathscr{I}_{k-1} \cup (\bm{x}_k, \mathcal{O}(x_k))\). \\
        Apply the rules of method \(\mathscr{M}\) to \(\mathscr{I}_k\) and generate a new point \(\bm{x}_{k+1}\). \\
        \eIf{\(\mathscr{I}_\epsilon\)}{
            Form output \(\solution\).
        }{
            \(k:= k+1\).
        }
    }
\end{algorithm}

Now we can specify the meaning of \emph{computational effort} in our definition of performance. In Algorithm~\ref{alg:general_iterative}, we can see two potentially expensive steps:
\begin{itemize}
    \item In Step 1, where we call the oracle.
    \item In Step 3, where we form a new test point.
\end{itemize}
So, we can introduce two measures of complexity of problem \(P\) for method \(\mathscr{M}\):
\newpage
\begin{defn}[Computational Complexity]\label{defn:complexity}
\textbf{{Analytical complexity}}: The number of calls of the oracle which is necessary to solve the problem \(P\) up to the accuracy \(\epsilon\).\\
\textbf{{Arithmetical complexity}}: The total number of arithmetic operations (including the work of oracle and work of method), which is necessary for solving problem \(P\) up to accuracy \(\epsilon\)
\end{defn}

Actually, the second one is more realistic. However, for a particular method \(\mathscr{M}\) as applied to problem \(P\), arithmetical complexity can be easily obtained from the analytical complexity and complexity of the oracle.

There is one standard assumption on the oracle which allows us to obtain the majority of results on analytical complexity for optimization schemes. This assumption, called \emph{Local Black Box Concept}, is as follows.

\begin{assum}[Local Black Box]\label{assum:local_black_box}
    \begin{enumerate}
        \item The only information available for the numerical scheme is the \emph{answer of the oracle}.
        \item The oracle is \emph{local}: A small variation of the problem far enough from the test point \(x\), which is compatible with the description of the problem class, does not change the answer at \(x\).
    \end{enumerate}
\end{assum}

In Assumption~\ref{assum:local_black_box}, the first one seems like the artificial wall between the method and the oracle. Although it seems natural to give methods full access to the internal structure of the problem,
we can find that when problems have a complicated or implicit structure, this access is almost useless.

Here we conclude problem~\ref{eq:general_min_problem} as a \emph{functional model} of optimization problem. According to the degree of smoothness, we can apply different types of oracle:
\begin{itemize}
    \item Zero-order Oracle: returns the function value \(f(\bm{x})\).
    \item First-order Oracle: returns the function value \(f(\bm{x})\) and the gradient \(\grad f(\bm{x})\).
    \item Second-order Oracle: returns \(f(\bm{x})\), \(\grad f(\bm{x})\), and the Hessian \(\grad^2 f(\bm{x})\)
\end{itemize}

\begin{boxnote}{Summerization}
    \begin{itemize}
        \item Usually we focus on the performance of method \(\mathscr{M}\) on a problem class \(\mathscr{P}\), rather than a particular problem. There are also 2 import concepts about problem: \emph{model} and \emph{oracle}.
        \item The performance of method \(\mathscr{M}\) on a problem class \(\mathscr{P}\) is defined as the total amount computational effort required by the method \(\mathscr{M}\) to solve the problem \(P\), just as Definition~\ref{defn:performance}.
              \begin{itemize}
                \item Computational complexity: \emph{Analytical} and \emph{Arithmetical}, just as Definition~\ref{defn:complexity}.
                \item Solving the problem: finding an \emph{approximate solution} with accuracy \(\epsilon > 0\).
              \end{itemize}
        \item We can use \emph{General Iterative Scheme} in Algorithm~\ref{alg:general_iterative} to deal with most of optimization problems.
        \item Standard assumption on oracle: \emph{Local Black Box Assumption} in Assumption~\ref{assum:local_black_box}.
    \end{itemize}
\end{boxnote}

\subsection{Complexity Bounds for Global Optimization}\label{subsec:Complexity_Bounds_for_Global_Optimization}

Let's consider \emph{\(n\)-dimensional box problem}:
\begin{equation}\label{eq:n_dimensional_box}
    \begin{aligned}
        & \min_{x \in B_n} ~ f(\bm{x}) \\
        & B_n = \{ \bm{x} \in \R^n \mid 0 \le {x}^{(i)} \le 1, ~ i = 1, \dots, n \}
    \end{aligned}
\end{equation}
In our terminology, this is a constrained minimization problem without functional constraints. \(B_n\) is the basic feasible set, which can be seemed as a \(n\)-dimensional box.

Here we use \(l_\infty\)-norm to measure distances:
\[
    \norminf{\bm{x}} = \max_{1 \le i \le n} \abs{x^{(i)}}  
\]

Then we make the assumption:
\begin{assum}\label{assum:lipschitz_objective_func}
    the objective function \(f(\cdot): \R^n \to \R\) is \emph{Lipschitz continuous} on \(B_n\):
    \[
        \abs{f(\bm{x} - \bm{y})} \le L \norminf{\bm{x} - \bm{y}} \quad \forall \bm{x},\bm{y} \in B_n,
    \]
    with some constant L (\emph{Lipschitz constant}).
\end{assum}

Let us consider a very simple method for solving problem~\ref{eq:n_dimensional_box}, 
which is called \emph{Uniform Grid Method} \(\mathscr{G}(p)\).
\begin{algorithm}[!htbp]
\caption{Uniform Grid Method \(\mathscr{G}(p)\)}\label{alg:uniform_grid_method}
    \KwIn{\(p \ge 1\)}
    \KwOut{The minimal pair \((\solution, f(\solution))\).}
    Form \(p^n\) points
    \[
        \bm{x}_\alpha = \left( \frac{2i_1 - 1}{2p}, \frac{2i_2 - 1}{2p}, \dots, \frac{2i_n - 1}{2p} \right)^\top.  
    \]
    where \(\alpha \equiv (i_1, \dots, i_n) \in \{1, \dots, p\}^n\).
    
    Among all points \(\bm{x}_\alpha\), find the point \(\solution\) with the minimal value of the objective function.
\end{algorithm}

Thus, this method forms a uniform grid of the test points in the \(n\)-dimensional box, 
computes the best value of the objective function over the grid, and returns this value 
as an approximate solution to problem~\ref{eq:n_dimensional_box}. In our terminology, 
this is a zero-order iterative method without any influence from the accumulated information 
on the sequence of test points. Then let's focus on its efficiency estimate.

\begin{thm}\label{thm:grid_err1}
    Let \(f^*\) be a global optimization value of problem~\ref{eq:n_dimensional_box}. Then
    \[
        f(\solution) - f^* \le \frac{L}{2p}  
    \]
\end{thm}

\begin{proof}[of Theorem~\ref{thm:grid_err1}]
    For a multi-index \(\alpha = (i_1, \dots, i_n)\), define
    \[
        X_\alpha = \left\{ \bm{x} \in \R^n \arrowvert \norminf{\bm{x} - \bm{x}_\alpha} \le \frac{1}{2p} \right\}
    \]

    Obviously, \(\bigcup_{\alpha \in \{1, \dots, p\}^n} X_\alpha = B_n\).

    Let \(\bm{x}^*\) be a global solution of our problem. Then there exists a multi-index \(\alpha^*\) 
    such that \(\bm{x}^* \in X_{\alpha^*}\). Note that \(\norminf{\bm{x}^* - \bm{x}_{\alpha^*}} \le 1/2p\). 
    Therefore,
    \[
        f(\solution) - f(\bm{x}^*) \le f(\bm{x}_{\alpha^*}) - f(\bm{x}^*) \le \frac{L}{2p}
    \]
\end{proof}

Let us conclude with the definition of our problem class. We fix our goal as follows:
\begin{equation}\label{eq:goal_n_box}
    \text{Find} ~ \solution \in B_n : \quad f(\solution) - f(\bm{x}^*) \le \epsilon
\end{equation}

\begin{coro}\label{coro:upper_complexity_of_grid}
    According to~\ref{assum:lipschitz_objective_func} and
    ~\ref{thm:grid_err1}, the analytical complexity of problem 
    class~\ref{eq:n_dimensional_box} for method \(\mathscr{G}\) is at most
    \[
        \mathscr{A}(\mathscr{G}) = \left( \left\lfloor \frac{L}{2\epsilon} \right\rfloor +1 \right)^n .
    \]
\end{coro}

\begin{proof}[of Corollary~\ref{coro:upper_complexity_of_grid}]
    Take \(p = \left\lfloor \frac{L}{2\epsilon} \right\rfloor +1\). Then \(p \ge \frac{L}{2\epsilon}\), and, in view of Theorem~\ref{thm:grid_err1}, 
    we have \(f(\solution) - f(\bm{x}^*) \le \frac{L}{2p} \le \epsilon\). Note that we need to call the oracle at \(p^n\) points.
\end{proof}

Thus, \(\mathscr{A}(\mathscr{G})\) justifies an \emph{upper} complexity bound for our problem class.

But we still get some questions:
\begin{enumerate}
    \item It may happen that our proof is too rough and the real performance of method \(\mathscr{G}(p)\) is much better.
    \item We still cannot be sure that \(\mathscr{G}(p)\) is reasonable method for solving problem~\ref{eq:n_dimensional_box}. There could exist other schemes with much higher performance.
\end{enumerate}
In order to answer these questions, we need to derive the \emph{lower} complexity bounds for problem class~\ref{eq:n_dimensional_box}. The main features of such bounds are as follows.
\begin{itemize}
    \item They are based on the \emph{Black Box Concept} in Assumption~\ref{assum:local_black_box}.
    \item These bounds are valid for all reasonable iterative schemes. Thus, they provide us with a lower estimate for the analytical complexity of the problem class.
    \item Very often such bounds employ the idea of a \emph{resisting oracle}.
\end{itemize}

\begin{colorboxnote}{Resisting Oracle}
    A \emph{resisting oracle} tries to create the \emph{worst possible} problem for each particular method.
    \begin{itemize}
        \item It starts from an "empty" function and it tries to answer each call of the method in the worst way.
        \item The answers must be \emph{compatible} with the \emph{previous answers} and with \emph{description of the problem class}.
        \item After termination of the method, it is possible to \emph{reconstruct} a problem which perfectly fits the final informational set accumulated by the algorithm.
        \item If we run the method on this newborn problem, it will reproduce the same sequence of test points since it will have the same sequence of answers from the oracle.
    \end{itemize}
\end{colorboxnote}

\begin{example}
    Let's consider gradient descent on a Lipschitz-smooth, convex function \(f\) (a convex function whose gradient is Lipschitz-continuous). Gradient descent generates a sequence 
    of points \(\{\bm{x}_k\}_{k \in \N}\) which satisfies
    \[
        \bm{x}_{k+1} := \bm{x}_{k} - \gamma \grad f(\bm{x}_{k}).
    \]

    Now we are interested in the worst case analysis. We would like to find the "worst" sequence \(\{\bm{x}_k\}_{k \in \N}\}\) we could probably get given by gradient descent.
    But under the assumption that \(f\) is convex and Lipschitz-smooth, the resisting oracle here would give you "bad" values of \(\grad f(\bm{x}_k)\), which lead to slow convergence but
    are still "possible" in the sense that they are values for which we can construct a convex Lipschitz-smooth function whose gradient evaluated at \(\bm{x}_k\) gives the right values.

    \textbf{Attention}: There is no actual function \(f\) here.  There is only the oracle giving us values when we ask it for \(\grad f(\bm{x}_k)\). The oracle is constructed in such a way 
    that the values it returns could plausibly be the gradient values of some convex Lipschitz smooth function, but there is no fixed function that we start with.
\end{example}

\begin{thm}\label{thm:lower_complexity_of_grid}
    For \(\epsilon < \frac{1}{2}L\), the analytical complexity of problem class \(\mathscr{P}_\infty\) is at least \(\left\lfloor \frac{L}{2\epsilon} \right\rfloor^n\) calls of oracle.
\end{thm}

\begin{proof}[of Theorem~\ref{thm:lower_complexity_of_grid}]
    Let \(p = \left\lfloor \frac{L}{2\epsilon} \right\rfloor~(\ge 1)\). Assume that there exists a method which needs \(N < p^n\) calls of oracle to solve any problem. Let us apply this method to the following resisting oracle:
    \[
        \text{Return} ~ f(\bm{x}) = 0 ~ \text{at any test point} ~  \bm{x}.
    \]
    Therefore this method can find only \(\solution \in B_n\) with \(f(\solution) = 0\).

    However, since \(N < p^n\), there exists a multi index \(\hat{\alpha}\) such that there were no test points in the box \(X_{\hat{\alpha}}\). Define \(\bm{x}_* = \bm{x}_{\hat{\alpha}}\), and consider the function
    \[
        \bar{f}(\bm{x}) = \min \{ 0, L\norminf{\bm{x} - \bm{x}_*} - \epsilon \}.  
    \]
    Clearly, this function is \(l_\infty\)-Lipschitz continuous with constant \(L\), and its global optimal value is \(-\epsilon\).
    Moreover, \(\forall \bm{x} \notin X_{\hat{\alpha}},~\bar{f}(\bm{x}) \ne 0\). Thus, \(\bar{f}(\cdot)\) is equal to zero \emph{at all test points} of our 
    method (\emph{since we assume that there is no test points in \(X_{\hat{\alpha}}\).})

    Since the accuracy of the output of our method is \(\epsilon\), we come to the following conclusion: \textbf{If the number of calls of the oracle is less than \(p^n\), then the accuracy of the result cannot be better than \(\epsilon\)}.

    Thus, the desired statement is proved.
\end{proof}

\begin{thm}\label{thm:upper_lower_bounds}
    Let us compare its efficiency estimate with the lower bound:
    \[
        \mathscr{G}: \left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\right)^n \Leftrightarrow \text{Lower bound:}~\left\lfloor \frac{L}{2\epsilon} \right\rfloor^n
    \]

    If \(\epsilon \le O\left( \frac{L}{n} \right)\), then the lower and upper bounds coincide up to an absolute constant multiplicative factor. This means that, for such level of accuracy,
    \(\mathscr{G}(\cdot)\) is \emph{optimal} for the problem class \(\mathscr{P}_\infty\).
\end{thm}

\begin{proof}[of Theorem~\ref{thm:upper_lower_bounds}]
    Since \(\epsilon \le O\left( \frac{L}{n} \right)\), there exists \(M > 0\) that satisfies
    \[
        \epsilon \le M \abs{\frac{L}{n}} = M \frac{L}{n} \Leftrightarrow \frac{L}{2\epsilon} \ge \frac{n}{2M}.
    \]
    So we can get
    \[
        1 \le \frac{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\right)^n}{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor\right)^n} 
        = 1 + \sum_{k=1}^n\frac{c_k}{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor\right)^k} 
        \le 1 + \sum_{k=1}^n\frac{C_n^k}{\left(\left\lfloor \frac{n}{2M} \right\rfloor\right)^k}.
    \]
    As \(n \to \infty\), we can also get
    \[
        \lim_{n\to\infty}\left[1 + \sum_{k=1}^n\frac{c_k}{\left(\left\lfloor \frac{n}{2M} \right\rfloor\right)^k}\right] = 1.
    \]
    So we can get the result based on \emph{Sandwich theorem}:
    \[
        \lim_{n \to \infty} \frac{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\right)^n}{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor\right)^n} = 1.
    \]
    Therefore, the statement is proofed.
\end{proof}

Theorem~\ref{thm:lower_complexity_of_grid} supports our initial claim that the general optimization problems are \emph{unsolvable}. Let us look the following example.

\begin{colorboxnote}{Example}
    Consider the problem class \(\mathscr{P}_\infty\) defined by the following parameters: \(L = 2\), \(n = 10\), \(\epsilon = 0.01\).
    The lower complexity bound for this class is \(\left\lfloor \frac{L}{2\epsilon} \right\rfloor^n\) calls of oracle. Let us compute this value for our example.
    \begin{itemize}
        \item \textbf{Lower bound}: \(10^{20}\) calls of the oracle
        \item \textbf{Oracle Complexity}: at least \(n\) arithmetic operations (a.o.)
        \item \textbf{Total Complexity}: \(10^{21}\) a.o.
        \item \textbf{Processor Performance}: \(10^6\) a.o. per second
        \item \textbf{Total Time}: \(10^{15}\)s
        \item \textbf{One year}: less than \(3.2\times 10^7\) s
        \item \textbf{We need}: \(31,250,000\) years.
    \end{itemize}
\end{colorboxnote}

This estimate is so disappointing that we cannot maintain any hope that such problems may become solvable in the future. The lower complexity bounds for problems 
with smooth functions, or for high-order methods, are not much better than the bound of Theorem~\ref{thm:lower_complexity_of_grid}.

\begin{boxnote}{Summerization}
    We aim to find the complexity bounds for global optimization. Here we use the example of \emph{\(n\)-dimensional box problem} just as~\ref{eq:n_dimensional_box}. 
    \begin{itemize}
        \item In order to deal with this kind of problems, we propose the \emph{Uniform Grid Method \(\mathscr{G}(p)\)} just as Algorithm~\ref{alg:uniform_grid_method}. 
              The computational complexity is \(p^n\) at most. So the question is: in order to Let the accuracy get to \(\epsilon > 0\), how should \(p\) be set?
        \item Here we assume that the objective function \(f(\cdot)\) is \emph{Lipschitz continuous} in Assumption~\ref{assum:lipschitz_objective_func}. Based on the condition of Lipschitz continuous,
              we can get the relationship between \(f(\solution)\) and \(f^*\) according to Theorem~\ref{thm:grid_err1}: \(f(\solution) - f^* \le \frac{L}{2p}\). 
        \item So, in order to satisfy \(f(\solution) - f^* \le \frac{L}{2p} \le \epsilon\), we can set \(p =\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\). So the upper complexity is 
              \(\mathscr{A}(\mathscr{G}) = p^n = \left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\right)^n\) just as Corollary~\ref{coro:upper_complexity_of_grid}.
        \item Based on \emph{resisting oracle}, we can get the lower complexity bound for Uniform Grid Method \(\mathscr{G}(p)\) is \(\left\lfloor \frac{L}{2\epsilon}^n \right\rfloor\) in Theorem~\ref{thm:lower_complexity_of_grid}.
    \end{itemize}
\end{boxnote}

At the end of this section, let us compare our observations with other fields. The uniform grid approach is a standard tool in many domains. Let's consider the numerical integral of a univariate function
\[
    \mathscr{J} = \int_{0}^1 f(x) \dd x \quad \Rightarrow \quad S_N = \frac{1}{N} \sum_{i=1}^m f(x_i).
\]
If \(f(\cdot)\) is Lipschitz continuous, then the value is good approximation to \(\mathscr{J}\):
\[
    N = L / \epsilon  \quad \Rightarrow \quad \abs{\mathscr{J} - S_N} \le \epsilon.
\]
This is a standard way for approximating integrals. The reason why it works here is related to \emph{dimension} of the problem. For integration, the standard dimensions are very small (up to three). However, in optimization, sometimes we need to
solve problems with several million variables.

\subsection{Identity Cards of the Fields}\label{subsec:Identity_Cards_of_the_Fields}

We try to find a reasonable target in the theoretical analysis of optimization schemes. It seems that everything is clear with general Global Optimization. However:
\begin{itemize}
    \item Maybe the goals of this field are too ambitious?
    \item In some practical problems could we be satisfied by much less "optimal" solutions?
    \item Are there some interesting problem classes which are not as dangerous as the class of general continuous functions?
\end{itemize}

In fact, each of these questions can be answered in different ways. In the field of nonlinear optimization, they differ one from another in the following aspects:
\begin{itemize}
    \item Goals of the methods.
    \item Classes of functional components.
    \item Description of an oracle.
\end{itemize}

These aspects naturally define the list of desired properties of the optimization methods, just as follows.

\begin{colorboxnote}{General Global Optimization}
    \begin{itemize}
        \item \textbf{Goals}: Find a global minimum.
        \item \textbf{Functional Class}: Continuous functions.
        \item \textbf{Oracle}: \(0-1-2\) order Black Box
        \item \textbf{Desired Properties}: Convergence to a global minimum.
        \item \textbf{Features}: From theoretical point of view, this game is too short.
        \item \textbf{Problem Sizes}: Sometimes, we can solve problems with many variables. No guarantee of success even for small problems.
    \end{itemize}
\end{colorboxnote}

\begin{colorboxnote}{General Nonlinear Optimization}
    \begin{itemize}
        \item \textbf{Goals}: Find a local minimum.
        \item \textbf{Functional Class}: Differentiable functions.
        \item \textbf{Oracle}: \(1\)-st and \(2\)-nd-order Black Box.
        \item \textbf{Desired Properties}: Fast convergence to a local minimum.
        \item \textbf{Features}: Variability of approaches. Most widespread software. The goals are not always acceptable and reachable.
        \item \textbf{Problem Sizes}: Up to several thousand variables.
    \end{itemize}
\end{colorboxnote}

\begin{colorboxnote}{Black Box Convex Optimization}
    \begin{itemize}
        \item \textbf{Goals}: Find a global minimum.
        \item \textbf{Functional Class}: Convex sets and functions.
        \item \textbf{Oracle}: \(1\)-st and \(2\)-nd-order Black Box.
        \item \textbf{Desired Properties}: Convergence to a global minimum. The convergence rate may depend on dimension.
        \item \textbf{Features}: Very interesting and rich on complexity theory. Efficient practical methods. The problem class is sometimes restrictive.
        \item \textbf{Problem Sizes}: Several thousand variables for the \(2\)-nd order methods, and several million for the \(1\)-st order schemes.
    \end{itemize}
\end{colorboxnote}

\begin{colorboxnote}{Structural Optimization}
    \begin{itemize}
        \item \textbf{Goals}: Find a global minimum.
        \item \textbf{Functional Class}: Simple convex sets and functions with explicit minmax structure.
        \item \textbf{Oracle}: \(2\)-nd-order Black Box for special barrier functions and modified \(1\)-st-order Black Box.
        \item \textbf{Desired Properties}: Fast convergence to a global minimum. The convergence rate may depend on the structure of the problem.
        \item \textbf{Features}: Very new and perspective theory rejecting the Black Box concept. The problem class is practically the same as in Convex optimization.
        \item \textbf{Problem Sizes}: Sometimes up to several million variables
    \end{itemize}
\end{colorboxnote}

\newpage

\section{Local Methods in Unconstrained Minimization}\label{sec:local_methods_in_unconstrained_min}

In this section, we consider several methods for solving the following unconstrained minimization problem:
\begin{equation}\label{eq:unconstrained_nonlinear_problem}
    \min_{\bm{x} \in \R^n} f(\bm{x}),
\end{equation}
where \(f(\cdot)\) is a smooth function.

\subsection{Relaxation and Approximation}\label{subsec:relax_approx}

The simplest goal in general Nonlinear Optimization consists in \emph{finding a local minimum of a differentiable function}. 
The majority of methods in general Nonlinear Optimization are based on the idea of \emph{relaxation}.

\begin{defn}[Relaxation]\label{defn:relaxation}
    A sequence of real numbers \(\{ a_k \}_{k=0}^\infty\) is called a \emph{relaxation sequence} if 
    \[
        a_{k+1} \le a_k \quad \forall k > 0. 
    \]
\end{defn}

In order to deal with problem~\ref{eq:unconstrained_nonlinear_problem}, most of methods generate a relaxation sequence of function values \(\{ f(\bm{x}_k) \}_{k=0}^{\infty}\):
\[
    f(\bm{x}_{k+1}) \le f(\bm{x}_k), \quad k = 0, 1, \dots ~.  
\]
This rule has the following important advantages:
\begin{enumerate}
    \item If \(f(\cdot)\) is bounded below on \(\R^n\), then the sequence \(\{ f(\bm{x}_k) \}_{k=0}^{\infty}\) converges.
    \item In any case, we improve the initial value of the objective function.
\end{enumerate}

In the meanwhile, there is another concept which is essential to implement the idea of relaxation. That is \emph{approximation}.
\begin{defn}[Approximation]\label{defn:approx}
    To approximate means to replace an initial complex object by a simper one which is close to the original in terms of its properties.
\end{defn}

In Nonlinear Optimization, we usually apply \emph{local approximation} based on derivatives of nonlinear functions. These are \(1\)-st- and \(2\)-nd-order approximations (or, the linear and quadratic approximations).

\begin{defn}[Linear Approximation]\label{defn:linear_approx}
    Let the function \(f(\cdot)\) be differentiable at \(\solution \in \R^n\). Then, for any \(\bm{y} \in \R^n\) we have
    \[
        f(\bm{y}) = f(\solution) + \innerprod{\grad f(\solution)}{\bm{y} - \solution} + o(\norm{\bm{y} - \solution}),
    \]
    where \(\grad f(\solution)\) is called the \emph{gradient} of the function \(f\) at \(\solution\). \(o(\cdot): [0, \infty) \to \R\) is a function of \(r \ge 0\) satisfying the conditions
    \[
        \lim_{r\to0} \frac{1}{r} o(r) = 0, \quad o(0) = 0. 
    \]
\end{defn}

Here we use the notation \(\norm{\cdot}\) for the standard \emph{Euclidean} norm in \(\R^n\):
\[
    \norm{\bm{x}} = \left[ \sum_{i=1}^n \left( x^{(i)} \right)^2 \right]^{1/2} = (\bm{x}^\top \bm{x})^{1/2} = \innerprod{\bm{x}}{\bm{x}}^{1/2},
\]
where \(\innerprod{\cdot}{\cdot}\) is the standard inner product in corresponding coordinate space. Note that
\[
    \forall \bm{x} \in \R^n,~\bm{y} \in \R^m, \bm{A} \in \R^{m \times n} \quad \Rightarrow \quad \innerprod{\bm{A}\bm{x}}{\bm{y}} \equiv \innerprod{\bm{x}}{\bm{A}^\top\bm{y}},
\] 

\begin{note}{Gradient}
    Consider the points: \(\bm{y}_i = \solution + \epsilon \bm{e}_i\), where \(\bm{e}_i\) is the \(i\)-th coordinate vector in \(\R^n\), and taking \(\epsilon \to 0\), we can get the following representation of the gradient:
    \begin{equation}\label{eq:grad}
        \grad f(\bm{x}) = \left( \pdv{f(\solution)}{x^{(1)}}, \dots, \pdv{f(\solution)}{x^{(n)}} \right)^\top
    \end{equation}
    Here we mention two important properties of the gradient. Denote by \(\mathscr{L}_f(\alpha)\) the \emph{(sub)level set} of \(f(\cdot)\):
    \[
        \mathscr{L}_f(\alpha) = \{ \bm{x} \in \R^n \mid f(\bm{x}) \le \alpha \}.
    \] 
    Consider the set of directions that are \emph{tangent} to \(\mathscr{L}_f(f(\solution))\) at \(\solution\):
    \[
        S_f(\solution) = \left\{
            \bm{s} \in \R^n \mid \bm{s} = \lim_{k \to \infty} \frac{\bm{y}_k - \solution}{\norm{\bm{y}_k - \solution}},
            ~\text{for some}~\{\bm{y}_k\} \to \solution ~\text{with}~ f(\bm{y}_k) = f(\solution) ~ \forall k
        \right\}.
    \]

    \begin{lemma}\label{lemma:s_grad}
        If \(\bm{s} \in S_f(\solution)\), then \(\innerprod{\grad f(\solution)}{\bm{s}} = 0\).
    \end{lemma}
    
    \begin{proof}[of Lemma~\ref{lemma:s_grad}]
        Since \(f(\bm{y}_k) = f(\solution)\), we can get
        \[
            f(\bm{y}_k) = f(\solution) + \innerprod{\grad f(\solution)}{\bm{y}_k - \solution} + o(\norm{\bm{y}_k - \solution}) = f(\solution).
        \]
        Therefore \(\innerprod{\grad f(\solution)}{\bm{y}_k - \solution} + o(\norm{\bm{y}_k - \solution}) = 0\). So dividing the equation by \(\norm{\bm{y}_k - \solution}\) and
        taking the limit as \(\bm{y}_k \to \solution\), we can obtain the result.
    \end{proof}

    \begin{colorboxnote}{The Fastest Local Decrease}
        Let \(\bm{s}\) be a direction in \(\R^n\), \(\norm{\bm{s}}\) = 1. Consider the local decrease of the function \(f(\cdot)\) along the direction \(\bm{s}\):
        \[
            \begin{aligned}
                \Delta(\bm{s}) = &\lim_{\alpha \to 0} \frac{1}{\alpha} [f(\solution + \alpha \bm{s}) - f(\solution)]\\
                &= \lim_{\alpha \to 0}\frac{1}{\alpha}[\alpha \innerprod{\grad f(\solution)}{\bm{s}} + o(\alpha)]\\
                &= \innerprod{\grad f(\solution)}{\bm{s}}
            \end{aligned}
        \] 
        Based on Cauchy-Schwarz inequality \( -\norm{\bm{x}}\cdot\norm{\bm{y}} \le \innerprod{\bm{x}}{\bm{y}} \le \norm{\bm{x}}\cdot\norm{\bm{y}} \), 
        we can obtain that \(\Delta(\bm{s}) = \innerprod{\grad f(\solution)}{\bm{s}} \ge -\norm{\grad f(\solution)}\). 
        Let us take \(\bar{\bm{s}} = -\grad f(\solution) / \norm{\grad f(\solution)}\), then
        \[
            \Delta(\bm{s}) = -\innerprod{\grad f(\solution)}{\grad f(\solution)} / \norm{\grad f(\solution)} = - \norm{\grad f(\solution)}.
        \]
        Thus, the direction of \(-\grad f(\solution)\) (\emph{the anti-gradient}) is the direction of the \emph{fastest local decrease} of the function \(f(\cdot)\) at point \(\solution\).
    \end{colorboxnote}
\end{note}

\begin{thm}[First-Order Optimality Condition]\label{thm:1st_order_optimal}
    Let \(\bm{x}^*\) be a local minimum of a differentiable function \(f(\cdot)\). Then
    \begin{equation}\label{eq:1st_order_optimal}
        \grad f(\bm{x}^*) = 0.
    \end{equation}
\end{thm}

\begin{proof}[of Theorem~\ref{thm:1st_order_optimal}]
    Since \(\bm{x}^*\) is a local minimum of \(f(\cdot)\),
    \[
      \exists r > 0,~\forall \bm{y} \in \R^n ~ \norm{\bm{y} - \bm{x}} < r,  \quad \text{s.t.}~ f(\bm{y}) \ge f(\bm{x}^*).
    \] 
    Since \(f(\cdot)\) is \emph{differentiable}, we can infer that
    \[
        f(\bm{y}) = f(\bm{x}^*) + \innerprod{\grad f(\bm{x}^*)}{\bm{y} - \bm{x}^*} + o(\norm{\bm{y} - \bm{x}^*}) \ge f(\bm{x}^*).
    \]
    Thus \(\forall \bm{s} \in \R^n\), we have \(\innerprod{\grad f(\bm{x}^*)}{\bm{s}} \ge 0\). By taking \(\bm{s} = -\grad f(\bm{x}^*)\), 
    we get \(-\norm{\grad f(\bm{x}^*})^2 \ge 0\). Hence, \(\grad f(\bm{x}) = 0\).
\end{proof}

\begin{defn}[Quadratic Approximation]\label{defn:quad_approx}
    Let \(f(\cdot)\) be twice differentiable at \(\solution\). Then
    \begin{equation}\label{eq:quad_approx}
        f(\bm{y}) = f(\solution) + \innerprod{\grad f(\solution)}{\bm{y} - \solution}
        + \frac{1}{2} \innerprod{\hess f(\solution)(\bm{y} - \solution)}{\bm{y} - \solution}
        + o(\norm{\bm{y} - \solution}^2),
    \end{equation}
    where \(\hess f(\solution)\) is the \emph{Hessian} matrix of function \(f\) at \(\solution\) 
    and \(\bm{o}(\cdot): [0, \infty) \R^n\) is a continuous vector function satisfying the condition
    \[
        \lim_{r\to0}\frac{1}{r} \norm{\bm{o}(r)} = 0.  
    \]
\end{defn}

\begin{colorboxnote}{Hessian Matrix}
    For Hessian matrix \(\hess f(\solution)\):
    \begin{enumerate}
        \item \(\hess f(\solution)^{(i, j)} = \pdv{f(\solution)}{x^{(i)}}{x^{(j)}}\).
        \item \(\hess f(\solution)\) is a \emph{symmetric} matrix: \(\hess f(\solution) = \left[\hess f(\solution)\right]^\top\).
        \item The Hessian can be regarded as a \emph{derivative} of the vector \(\grad f(\cdot)\):
              \[
                    \grad f(\bm{y}) = \grad f(\solution) + \hess f(\solution) (\bm{y} - \solution) + \bm{o}(\norm{\bm{y} - \solution}) \in \R^n
              \]
    \end{enumerate}
\end{colorboxnote}

Based on the quadratic approximation, we can write down the \emph{second-order optimality condition}.

\begin{thm}[Second-Order Optimality Condition]\label{thm:2nd_order_optimal}
    Let \(\bm{x}^*\) be a local minimum of a twice differentiable function \(f(\cdot)\). Then
    \begin{equation}
        \grad f(\bm{x}^*) = 0, \quad \hess f(\bm{x}^*) \succeq 0.
    \end{equation}
\end{thm}

\begin{proof}[of Theorem~\ref{thm:2nd_order_optimal}]
    Since \(\bm{x}^*\) is a local minimum of the function \(f(\cdot)\), 
    \[
        \exists r > 0,~\forall \bm{y} \in \R^n ~ \norm{\bm{y} - \bm{x}} < r,  \quad \text{s.t.}~ f(\bm{y}) \ge f(\bm{x}^*).
    \]

    In view of Theorem~\ref{thm:1st_order_optimal}, \(\grad f(\bm{x}^*) = 0\). Therefore, for any such \(\bm{y}\),
    \[
        f(\bm{y}) = f(\bm{x}^*) + \innerprod{\hess f(\bm{x}^*)(\bm{y} - \bm{x}^*)}{\bm{y} - \bm{x}^*} + o(\norm{\bm{y} - \bm{x}^*}^2) \ge f(\bm{x}^*).  
    \]
    Thus, \(\innerprod{\hess f(\bm{x}^*) \bm{s}}{\bm{s}} \ge 0\), for all \(\bm{s}\), \(\norm{\bm{s}} = 1\).
\end{proof}

Again, Theorem~\ref{thm:2nd_order_optimal} is a \emph{necessary} (\(2\)-nd-order) characteristic of a local minimum. The \emph{sufficient} condition is as follows.

\begin{thm}\label{thm:suff_2nd_order_optimal}
    Let a function \(f(\cdot)\) be twice differentiable on \(\R^n\) and let \(\bm{x}^* \in \R^n\) satisfy the following conditions:
    \begin{equation}
        \grad f(\bm{x}^*) = 0, \quad \hess f(\bm{x}^*) \succ 0.
    \end{equation}
    Then \(\bm{x}^*\) is a strict local minimum of \(f(\cdot)\)
\end{thm}

\begin{proof}[of Theorem~\ref{thm:suff_2nd_order_optimal}]
    
\end{proof}