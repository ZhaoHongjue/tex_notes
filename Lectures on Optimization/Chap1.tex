\chapter{Nonlinear Optimization}\label{chap:nonlinear_optimization}

In this chapter, we mainly focus on:
\begin{itemize}
    \item Main notations and concepts used in \emph{Continuous Optimization}.
    \item Complexity Analysis of the problems of Global Optimization.
    \item Local Minimization and 2 main methods: \emph{the Gradient Method} and \emph{the Newton Method}.
    \item Some standard methods in General Nonlinear Optimization.
\end{itemize}

\section{The World of Nonlinear Optimization}\label{sec:the_world_of_nonlinear_optimization}

\subsection{General Formulation of the Problem}\label{subsec:general_formulation_of_the_problem}
Let \(\myvec{x}\) be an \(n\)-dimensional \emph{real vector}
\[
    \myvec{x} = \left( x^{(1)}, \dots, x^{(n)} \right)^\top \in \R^n
\]
and \(f_0(\cdot), \dots, f_m(\cdot)\) be some \emph{real-valued} functions defined on a set \(Q \subset \R^n\). In this way, let's consider the general minimization problem:
\begin{equation}\label{eq:general_min_problem}
    \begin{aligned}
        &\min ~ f_0(\myvec{x}), \\
        &\text{s.t.}~f_j(\myvec{x}) ~ \& ~ 0, \quad j = 1, \dots, m,\\
        &\myvec{x} \in Q,
    \end{aligned}
\end{equation}
where the sign \(\&\) can be \(\le\), \(\ge\) or \(=\).

\begin{note}{Notations}
    \begin{itemize}
        \item \(f_0\) is called \emph{objective} function.
        \item The vector function \(\myvec{f}(\myvec{x}) = \left( f_1(\myvec{x}), \dots, f_m(\myvec{x})^\top \right)\) is called the vector of \emph{functional constraints}.
        \item The set \(Q\) is called the \emph{basic feasible set}.
        \item The set \( \mathscr{F} = \{ x \in Q \mid f_j(\myvec{x}), ~j=1, \dots, m \}\) is called \emph{the entire feasible set} of problem~\ref{eq:general_min_problem}. 
    \end{itemize}
\end{note}

\begin{note}{Classification}
    \begin{enumerate}
        \item \textbf{Natural Classification}:
            \begin{itemize}
                \item \emph{Constrained problems}: \(\mathscr{F} \subset \R^n\).
                \item \emph{Unconstrained problems}: \(\mathscr{F} \equiv \R^n\).
                \item \emph{Smooth problems}: all \(f_j(\cdot)\) are differentiable.
                \item \emph{Nonsmooth problems}: there are several nondifferentiable components \(f_k(\cdot)\).
                \item \emph{Linearly constrained problems}: the functional constraints are affine:
                    \[
                            f_j(x) = \langle \myvec{a}_j, \myvec{x} \rangle + b_j
                    \]
                    \begin{itemize}
                        \item \emph{Linear optimization Problem}: \(f_0(\cdot)\) is also affine.
                        \item \emph{Quadratic optimization problem}: \(f_0(\cdot)\) is Quadratic.
                        \item \emph{Quadratic constrained quadratic problem}: \(f_0(\cdot), \dots, f_m(\cdot)\) are all quadratic.
                    \end{itemize}
            \end{itemize}
        \item \textbf{Based on the Feasible Set}:
            \begin{itemize}
                \item Problem~\ref{eq:general_min_problem} is called \emph{feasible} if \(\mathscr{F} \ne \emptyset\).
                \item Problem~\ref{eq:general_min_problem} is called \emph{strictly} feasible if there exists an \(\myvec{x} \in Q\) such that \(f_j(\myvec{x}) < 0\) for all inequality constraints and \(f_j(\myvec{x}) = 0\) for all equality constraints. (\textit{Slater condition}.)
            \end{itemize}
        \item \textbf{Based on Solution}:
            \begin{itemize}
                \item A point \(\myvec{x}^* \in \mathscr{F}\) is called the optimal \emph{global solution} to problem~\ref{eq:general_min_problem} if \(f_0(\myvec{x}^*) \le f_0(\myvec{x})\) for all \(\myvec{x} \in \mathscr{F}\) (\textit{global minimum}). \(f_0(\myvec{x}^*)\) is called the global \emph{optimal value} of the problem.
                \item A point \(\myvec{x}^* \in \mathscr{F}\) is called a \emph{local solution} to problem~\ref{eq:general_min_problem} if there exists a set \(\hat{\mathscr{F}} \subset \mathscr{F}\) such that \(\forall \myvec{x} \in \mathrm{int}\hat{\mathscr{F}}, ~f_0(\myvec{x}^*) \le f_0(\myvec{x})\). If \(\forall \myvec{x} \in \hat{\mathscr{F}} \setminus \{\myvec{{x}^*}\}, ~f_0(\myvec{x}^*) \le f_0(\myvec{x})\), then \(\myvec{x}^*\) is called \emph{strict} (or \emph{isolated}) local minimum.
            \end{itemize}
    \end{enumerate}
\end{note}

Nonlinear Optimization is very import and promising application theory. It covers almost ALL needs of Operation Research and Numerical Analysis. However, in general, optimization problems should be UNSOLVABLE. It is difficult to believe in the existence of a universal tool which is able to solve all problems in the world.

\begin{boxnote}{Summerization}
    \begin{itemize}
        \item First we learn the general formulation of optimization problem in~\ref{eq:general_min_problem} and related concepts.
        \item We can also classify the optimization problems into different categories. The classification methods include:
              \begin{itemize}
                \item Natural Classification.
                \item Based on Feasible Set.
                \item Based on Solution.
              \end{itemize} 
    \end{itemize}
\end{boxnote}

\subsection{Performance of Numerical Methods}\label{subsec:performance_of_numerical_performance}
Usually we focus on the best method for a \emph{class} of problem \(\mathscr{P} \ni P\). The \emph{performance} of a method, \(\mathscr{M}\) on the whole class \(\mathscr{P}\) can be a natural measure of its efficiency. Here we assume that the method \(\mathscr{M}\) does not have \emph{complete} information about a particular problem \(P\).
\begin{itemize}
    \item \textbf{Model}: The \emph{model} is the \emph{known} (to a numerical scheme) "part" of problem \(P\) and is denoted by \(\Sigma\). The model consists of:
        \begin{itemize}
            \item The formulation of the problem.
            \item The description of the classes of functional components.
            \item etc.
        \end{itemize}    
    \item \textbf{Oracle}: The oracle is used to describe the process of collecting this data. A oracle \(\mathcal{O}\) is just a unit which answers the successive questions of the methods.
\end{itemize}
The method \(\mathscr{M}\) is trying to solve the problem \(P\) by collecting and handling the answers. 

For each problem we can develop different types of oracles. But let us fix \(\Sigma\) and \(\mathcal{O}\). In this case, it is natural to define the performance of \(\mathscr{M}\) on \((\Sigma, \mathcal{O})\) as its performance on the worst \(P_w\) from \((\Sigma, \mathcal{O})\). Note that \(P_w\) can be only bad for \(\mathscr{M}\).

\begin{defn}[Performance]\label{defn:performance}
    The performance of \(\mathscr{M}\) on \(P\) is the total amount of \emph{computational effort} required by the method \(\mathscr{M}\) to solve the problem \(P\).
\end{defn}

\begin{note}{Notes}
    \begin{itemize}
        \item Solving the problem means finding an \emph{approximate solution} to \(\mathscr{P}\) with some accuracy \(\epsilon > 0\). 
        \item We use \(\mathscr{T}_\epsilon\) to represent a stopping criterion.
    \end{itemize}
\end{note}

Now we have a formal description of the problem class:
\[
    \mathscr{P} \equiv (\Sigma, \mathcal{O}, \mathscr{T}_\epsilon)    
\]

In order to solve a problem \(P\) from \(\mathscr{P}\), we apply it to an \emph{iterative process}.
\begin{algorithm}[!htbp]
    \caption{General Iterative Scheme}\label{alg:general_iterative}
    \KwIn{Starting point \(x_0\) and accuracy \(\epsilon > 0\).}
    \KwOut{Solution \(\bar{x}\).}
    \textbf{Initialization}: Set \(k = 0\), \(\mathscr{I}_{-1} = \emptyset\). Here \(k\) is the iteration counter and \(\mathscr{I}_k\) is the accumulated \emph{informational set}.\\
    \While{True}{
        Call oracle \(\mathcal{O}\) at point \(\myvec{x}_k\). \\
        Update the informational set: \(\mathscr{I}_k = \mathscr{I}_{k-1} \cup (\myvec{x}_k, \mathcal{O}(x_k))\). \\
        Apply the rules of method \(\mathscr{M}\) to \(\mathscr{I}_k\) and generate a new point \(\myvec{x}_{k+1}\). \\
        \eIf{\(\mathscr{I}_\epsilon\)}{
            Form output \(\bar{\myvec{x}}\).
        }{
            \(k:= k+1\).
        }
    }
\end{algorithm}

Now we can specify the meaning of \emph{computational effort} in our definition of performance. In Algorithm~\ref{alg:general_iterative}, we can see two potentially expensive steps:
\begin{itemize}
    \item In Step 1, where we call the oracle.
    \item In Step 3, where we form a new test point.
\end{itemize}
So, we can introduce two measures of complexity of problem \(P\) for method \(\mathscr{M}\):
\newpage
\begin{defn}[Computational Complexity]\label{defn:complexity}
\textbf{{Analytical complexity}}: The number of calls of the oracle which is necessary to solve the problem \(P\) up to the accuracy \(\epsilon\).\\
\textbf{{Arithmetical complexity}}: The total number of arithmetic operations (including the work of oracle and work of method), which is necessary for solving problem \(P\) up to accuracy \(\epsilon\)
\end{defn}

Actually, the second one is more realistic. However, for a particular method \(\mathscr{M}\) as applied to problem \(P\), arithmetical complexity can be easily obtained from the analytical complexity and complexity of the oracle.

There is one standard assumption on the oracle which allows us to obtain the majority of results on analytical complexity for optimization schemes. This assumption, called \emph{Local Black Box Concept}, is as follows.

\begin{assum}[Local Black Box]\label{assum:local_black_box}
    \begin{enumerate}
        \item The only information available for the numerical scheme is the \emph{answer of the oracle}.
        \item The oracle is \emph{local}: A small variation of the problem far enough from the test point \(x\), which is compatible with the description of the problem class, does not change the answer at \(x\).
    \end{enumerate}
\end{assum}

In Assumption~\ref{assum:local_black_box}, the first one seems like the artificial wall between the method and the oracle. Although it seems natural to give methods full access to the internal structure of the problem,
we can find that when problems have a complicated or implicit structure, this access is almost useless.

Here we conclude problem~\ref{eq:general_min_problem} as a \emph{functional model} of optimization problem. According to the degree of smoothness, we can apply different types of oracle:
\begin{itemize}
    \item Zero-order Oracle: returns the function value \(f(\myvec{x})\).
    \item First-order Oracle: returns the function value \(f(\myvec{x})\) and the gradient \(\grad f(\myvec{x})\).
    \item Second-order Oracle: returns \(f(\myvec{x})\), \(\grad f(\myvec{x})\), and the Hessian \(\grad^2 f(\myvec{x})\)
\end{itemize}

\begin{boxnote}{Summerization}
    \begin{itemize}
        \item Usually we focus on the performance of method \(\mathscr{M}\) on a problem class \(\mathscr{P}\), rather than a particular problem. There are also 2 import concepts about problem: \emph{model} and \emph{oracle}.
        \item The performance of method \(\mathscr{M}\) on a problem class \(\mathscr{P}\) is defined as the total amount computational effort required by the method \(\mathscr{M}\) to solve the problem \(P\), just as Definition~\ref{defn:performance}.
              \begin{itemize}
                \item Computational complexity: \emph{Analytical} and \emph{Arithmetical}, just as Definition~\ref{defn:complexity}.
                \item Solving the problem: finding an \emph{approximate solution} with accuracy \(\epsilon > 0\).
              \end{itemize}
        \item We can use \emph{General Iterative Scheme} in Algorithm~\ref{alg:general_iterative} to deal with most of optimization problems.
        \item Standard assumption on oracle: \emph{Local Black Box Assumption} in Assumption~\ref{assum:local_black_box}.
    \end{itemize}
\end{boxnote}

\subsection{Complexity Bounds for Global Optimization}\label{subsec:Complexity_Bounds_for_Global_Optimization}

Let's consider \emph{\(n\)-dimensional box problem}:
\begin{equation}\label{eq:n_dimensional_box}
    \begin{aligned}
        & \min_{x \in B_n} ~ f(\myvec{x}) \\
        & B_n = \{ \myvec{x} \in \R^n \mid 0 \le {x}^{(i)} \le 1, ~ i = 1, \dots, n \}
    \end{aligned}
\end{equation}
In our terminology, this is a constrained minimization problem without functional constraints. \(B_n\) is the basic feasible set, which can be seemed as a \(n\)-dimensional box.

Here we use \(l_\infty\)-norm to measure distances:
\[
    \norminf{\myvec{x}} = \max_{1 \le i \le n} \abs{x^{(i)}}  
\]

Then we make the assumption:
\begin{assum}\label{assum:lipschitz_objective_func}
    the objective function \(f(\cdot): \R^n \to \R\) is \emph{Lipschitz continuous} on \(B_n\):
    \[
        \abs{f(\myvec{x} - \myvec{y})} \le L \norminf{\myvec{x} - \myvec{y}} \quad \forall \myvec{x},\myvec{y} \in B_n,
    \]
    with some constant L (\emph{Lipschitz constant}).
\end{assum}

Let us consider a very simple method for solving problem~\ref{eq:n_dimensional_box}, 
which is called \emph{Uniform Grid Method} \(\mathscr{G}(p)\).
\begin{algorithm}[!htbp]
\caption{Uniform Grid Method \(\mathscr{G}(p)\)}\label{alg:uniform_grid_method}
    \KwIn{\(p \ge 1\)}
    \KwOut{The minimal pair \((\bar{\myvec{x}}, f(\bar{\myvec{x}}))\).}
    Form \(p^n\) points
    \[
        \myvec{x}_\alpha = \left( \frac{2i_1 - 1}{2p}, \frac{2i_2 - 1}{2p}, \dots, \frac{2i_n - 1}{2p} \right)^\top.  
    \]
    where \(\alpha \equiv (i_1, \dots, i_n) \in \{1, \dots, p\}^n\).
    
    Among all points \(\myvec{x}_\alpha\), find the point \(\bar{\myvec{x}}\) with the minimal value of the objective function.
\end{algorithm}

Thus, this method forms a uniform grid of the test points in the \(n\)-dimensional box, 
computes the best value of the objective function over the grid, and returns this value 
as an approximate solution to problem~\ref{eq:n_dimensional_box}. In our terminology, 
this is a zero-order iterative method without any influence from the accumulated information 
on the sequence of test points. Then let's focus on its efficiency estimate.

\begin{thm}\label{thm:grid_err1}
    Let \(f^*\) be a global optimization value of problem~\ref{eq:n_dimensional_box}. Then
    \[
        f(\bar{\myvec{x}}) - f^* \le \frac{L}{2p}  
    \]
\end{thm}

\begin{proof}[of Theorem~\ref{thm:grid_err1}]
    For a multi-index \(\alpha = (i_1, \dots, i_n)\), define
    \[
        X_\alpha = \left\{ \myvec{x} \in \R^n \arrowvert \norminf{\myvec{x} - \myvec{x}_\alpha} \le \frac{1}{2p} \right\}
    \]

    Obviously, \(\bigcup_{\alpha \in \{1, \dots, p\}^n} X_\alpha = B_n\).

    Let \(\myvec{x}^*\) be a global solution of our problem. Then there exists a multi-index \(\alpha^*\) 
    such that \(\myvec{x}^* \in X_{\alpha^*}\). Note that \(\norminf{\myvec{x}^* - \myvec{x}_{\alpha^*}} \le 1/2p\). 
    Therefore,
    \[
        f(\bar{\myvec{x}}) - f(\myvec{x}^*) \le f(\myvec{x}_{\alpha^*}) - f(\myvec{x}^*) \le \frac{L}{2p}
    \]
\end{proof}

Let us conclude with the definition of our problem class. We fix our goal as follows:
\begin{equation}\label{eq:goal_n_box}
    \text{Find} ~ \bar{\myvec{x}} \in B_n : \quad f(\bar{\myvec{x}}) - f(\myvec{x}^*) \le \epsilon
\end{equation}

\begin{coro}\label{coro:upper_complexity_of_grid}
    According to Assumption~\ref{assum:lipschitz_objective_func} and
    Theorem~\ref{thm:grid_err1}, the analytical complexity of problem 
    class~\ref{eq:n_dimensional_box} for method \(\mathscr{G}\) is at most
    \[
        \mathscr{A}(\mathscr{G}) = \left( \left\lfloor \frac{L}{2\epsilon} \right\rfloor +1 \right)^n .
    \]
\end{coro}

\begin{proof}[of Corollary~\ref{coro:upper_complexity_of_grid}]
    Take \(p = \left\lfloor \frac{L}{2\epsilon} \right\rfloor +1\). Then \(p \ge \frac{L}{2\epsilon}\), and, in view of Theorem~\ref{thm:grid_err1}, 
    we have \(f(\bar{\myvec{x}}) - f(\myvec{x}^*) \le \frac{L}{2p} \le \epsilon\). Note that we need to call the oracle at \(p^n\) points.
\end{proof}

Thus, \(\mathscr{A}(\mathscr{G})\) justifies an \emph{upper} complexity bound for our problem class.

But we still get some questions:
\begin{enumerate}
    \item It may happen that our proof is too rough and the real performance of method \(\mathscr{G}(p)\) is much better.
    \item We still cannot be sure that \(\mathscr{G}(p)\) is reasonable method for solving problem~\ref{eq:n_dimensional_box}. There could exist other schemes with much higher performance.
\end{enumerate}
In order to answer these questions, we need to derive the \emph{lower} complexity bounds for problem class~\ref{eq:n_dimensional_box}. The main features of such bounds are as follows.
\begin{itemize}
    \item They are based on the \emph{Black Box Concept} in Assumption~\ref{assum:local_black_box}.
    \item These bounds are valid for all reasonable iterative schemes. Thus, they provide us with a lower estimate for the analytical complexity of the problem class.
    \item Very often such bounds employ the idea of a \emph{resisting oracle}.
\end{itemize}

\begin{colorboxnote}{Resisting Oracle}
    A \emph{resisting oracle} tries to create the \emph{worst possible} problem for each particular method.
    \begin{itemize}
        \item It starts from an "empty" function and it tries to answer each call of the method in the worst way.
        \item The answers must be \emph{compatible} with the \emph{previous answers} and with \emph{description of the problem class}.
        \item After termination of the method, it is possible to \emph{reconstruct} a problem which perfectly fits the final informational set accumulated by the algorithm.
        \item If we run the method on this newborn problem, it will reproduce the same sequence of test points since it will have the same sequence of answers from the oracle.
    \end{itemize}
\end{colorboxnote}

\begin{example}
    Let's consider gradient descent on a Lipschitz-smooth, convex function \(f\) (a convex function whose gradient is Lipschitz-continuous). Gradient descent generates a sequence 
    of points \(\{\myvec{x}_k\}_{k \in \N}\) which satisfies
    \[
        \myvec{x}_{k+1} := \myvec{x}_{k} - \gamma \grad f(\myvec{x}_{k}).
    \]

    Now we are interested in the worst case analysis. We would like to find the "worst" sequence \(\{\myvec{x}_k\}_{k \in \N}\}\) we could probably get given by gradient descent.
    But under the assumption that \(f\) is convex and Lipschitz-smooth, the resisting oracle here would give you "bad" values of \(\grad f(\myvec{x}_k)\), which lead to slow convergence but
    are still "possible" in the sense that they are values for which we can construct a convex Lipschitz-smooth function whose gradient evaluated at \(\myvec{x}_k\) gives the right values.

    \textbf{Attention}: There is no actual function \(f\) here.  There is only the oracle giving us values when we ask it for \(\grad f(\myvec{x}_k)\). The oracle is constructed in such a way 
    that the values it returns could plausibly be the gradient values of some convex Lipschitz smooth function, but there is no fixed function that we start with.
\end{example}

\begin{thm}\label{thm:lower_complexity_of_grid}
    For \(\epsilon < \frac{1}{2}L\), the analytical complexity of problem class \(\mathscr{P}_\infty\) is at least \(\left\lfloor \frac{L}{2\epsilon} \right\rfloor^n\) calls of oracle.
\end{thm}

\begin{proof}[of Theorem~\ref{thm:lower_complexity_of_grid}]
    Let \(p = \left\lfloor \frac{L}{2\epsilon} \right\rfloor~(\ge 1)\). Assume that there exists a method which needs \(N < p^n\) calls of oracle to solve any problem. Let us apply this method to the following resisting oracle:
    \[
        \text{Return} ~ f(\myvec{x}) = 0 ~ \text{at any test point} ~  \myvec{x}.
    \]
    Therefore this method can find only \(\bar{\myvec{x}} \in B_n\) with \(f(\bar{\myvec{x}}) = 0\).

    However, since \(N < p^n\), there exists a multi index \(\hat{\alpha}\) such that there were no test points in the box \(X_{\hat{\alpha}}\). Define \(\myvec{x}_* = \myvec{x}_{\hat{\alpha}}\), and consider the function
    \[
        \bar{f}(\myvec{x}) = \min \{ 0, L\norminf{\myvec{x} - \myvec{x}_*} - \epsilon \}.  
    \]
    Clearly, this function is \(l_\infty\)-Lipschitz continuous with constant \(L\), and its global optimal value is \(-\epsilon\).
    Moreover, \(\forall \myvec{x} \notin X_{\hat{\alpha}},~\bar{f}(\myvec{x}) \ne 0\). Thus, \(\bar{f}(\cdot)\) is equal to zero \emph{at all test points} of our 
    method (\emph{since we assume that there is no test points in \(X_{\hat{\alpha}}\).})

    Since the accuracy of the output of our method is \(\epsilon\), we come to the following conclusion: \textbf{If the number of calls of the oracle is less than \(p^n\), then the accuracy of the result cannot be better than \(\epsilon\)}.

    Thus, the desired statement is proved.
\end{proof}

\begin{thm}\label{thm:upper_lower_bounds}
    Let us compare its efficiency estimate with the lower bound:
    \[
        \mathscr{G}: \left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\right)^n \Leftrightarrow \text{Lower bound:}~\left\lfloor \frac{L}{2\epsilon} \right\rfloor^n
    \]

    If \(\epsilon \le O\left( \frac{L}{n} \right)\), then the lower and upper bounds coincide up to an absolute constant multiplicative factor. This means that, for such level of accuracy,
    \(\mathscr{G}(\cdot)\) is \emph{optimal} for the problem class \(\mathscr{P}_\infty\).
\end{thm}

\begin{proof}[of Theorem~\ref{thm:upper_lower_bounds}]
    Since \(\epsilon \le O\left( \frac{L}{n} \right)\), there exists \(M > 0\) that satisfies
    \[
        \epsilon \le M \abs{\frac{L}{n}} = M \frac{L}{n} \Leftrightarrow \frac{L}{2\epsilon} \ge \frac{n}{2M}.
    \]
    So we can get
    \[
        1 \le \frac{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\right)^n}{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor\right)^n} 
        = 1 + \sum_{k=1}^n\frac{c_k}{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor\right)^k} 
        \le 1 + \sum_{k=1}^n\frac{C_n^k}{\left(\left\lfloor \frac{n}{2M} \right\rfloor\right)^k}.
    \]
    As \(n \to \infty\), we can also get
    \[
        \lim_{n\to\infty}\left[1 + \sum_{k=1}^n\frac{c_k}{\left(\left\lfloor \frac{n}{2M} \right\rfloor\right)^k}\right] = 1.
    \]
    So we can get the result based on \emph{Sandwich theorem}:
    \[
        \lim_{n \to \infty} \frac{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\right)^n}{\left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor\right)^n} = 1.
    \]
    Therefore, the statement is proofed.
\end{proof}


\begin{boxnote}{Summerization}
    We aim to find the complexity bounds for global optimization. Here we use the example of \emph{\(n\)-dimensional box problem} just as~\ref{eq:n_dimensional_box}. 
    \begin{itemize}
        \item In order to deal with this kind of problems, we propose the \emph{Uniform Grid Method \(\mathscr{G}(p)\)} just as Algorithm~\ref{alg:uniform_grid_method}. 
              The computational complexity is \(p^n\) at most. So the question is: in order to Let the accuracy get to \(\epsilon > 0\), how should \(p\) be set?
        \item Here we assume that the objective function \(f(\cdot)\) is \emph{Lipschitz continuous} in Assumption~\ref{assum:lipschitz_objective_func}. Based on the condition of Lipschitz continuous,
              we can get the relationship between \(f(\bar{\myvec{x}})\) and \(f^*\) according to Theorem~\ref{thm:grid_err1}: \(f(\bar{\myvec{x}}) - f^* \le \frac{L}{2p}\). 
        \item So, in order to satisfy \(f(\bar{\myvec{x}}) - f^* \le \frac{L}{2p} \le \epsilon\), we can set \(p =\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\). So the upper complexity is 
              \(\mathscr{A}(\mathscr{G}) = p^n = \left(\left\lfloor \frac{L}{2\epsilon} \right\rfloor + 1\right)^n\) just as Corollary~\ref{coro:upper_complexity_of_grid}.
    \end{itemize}
\end{boxnote}

\subsection{Identity Cards of the Fields}\label{subsec:Identity_Cards_of_the_Fields}